{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on masked tokens in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize sequences, preserving `[MASK]` as a single token\n",
    "def add_spaces_preserve_mask(sequence):\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        if sequence[i : i + 6] == \"[MASK]\":  # Detect `[MASK]`\n",
    "            tokens.append(\"[MASK]\")\n",
    "            i += 6  \n",
    "        else:\n",
    "            tokens.append(sequence[i])\n",
    "            i += 1\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Function to predict the masked tokens from the tokenized sequence\n",
    "def recover_sequence(sequence, model_unmasker):\n",
    "    tokens = sequence.split()  # Tokenize the sequence\n",
    "    result = model_unmasker(\" \".join(tokens)) # Predictions\n",
    "    \n",
    "    mask_index = 0  \n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == \"[MASK]\":\n",
    "            top_prediction = result[mask_index][0][\"token_str\"]\n",
    "            tokens[i] = top_prediction\n",
    "            mask_index += 1  \n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Function to calculate overall accuracy and recover the masked tokens\n",
    "def calculate_accuracy_and_recover(test_data, model_unmasker):\n",
    "    correct_predictions = 0\n",
    "    total_masked_tokens = 0\n",
    "    recovered_sequences = []\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        original_seq = row[\"OriginalSequence\"]\n",
    "        masked_seq = row[\"MaskedSequence\"]\n",
    "\n",
    "        original_seq_spaced = add_spaces_preserve_mask(original_seq)\n",
    "        masked_seq_spaced = add_spaces_preserve_mask(masked_seq)\n",
    "\n",
    "        recovered_seq = recover_sequence(masked_seq_spaced, model_unmasker)\n",
    "        recovered_sequences.append(recovered_seq)\n",
    "\n",
    "        # Compare only the masked tokens\n",
    "        original_seq_tokens = original_seq_spaced.split()\n",
    "        masked_seq_tokens = masked_seq_spaced.split()\n",
    "        recovered_seq_tokens = recovered_seq.split()\n",
    "        for orig, masked, recovered in zip(original_seq_tokens, masked_seq_tokens, recovered_seq_tokens):\n",
    "            if masked == \"[MASK]\":  \n",
    "                total_masked_tokens += 1\n",
    "                if orig == recovered:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "    # Calculate accuracy and error rate\n",
    "    accuracy = correct_predictions / total_masked_tokens if total_masked_tokens > 0 else 0\n",
    "    error_rate = 1 - accuracy\n",
    "\n",
    "    return recovered_sequences, accuracy, error_rate\n",
    "\n",
    "# Functions to calculate region-level accuracy and error rate\n",
    "def add_region_accuracy(region_accuracies, start, end, region_name, original, masked, recovered):\n",
    "    \"\"\"Helper function to calculate accuracy for a specific region.\"\"\"\n",
    "    for orig, mask, rec in zip(original[start:end], masked[start:end], recovered[start:end]):\n",
    "        if mask == \"[MASK]\":\n",
    "            region_accuracies[region_name][\"total\"] += 1\n",
    "            if orig == rec:\n",
    "                region_accuracies[region_name][\"correct\"] += 1\n",
    "\n",
    "\n",
    "def calculate_accuracy_by_region(test_data, model_unmasker):\n",
    "    region_accuracies = {\n",
    "        \"FWH1\": {\"correct\": 0, \"total\": 0},\n",
    "        \"CDRH1\": {\"correct\": 0, \"total\": 0},\n",
    "        \"FWH2\": {\"correct\": 0, \"total\": 0},\n",
    "        \"CDRH2\": {\"correct\": 0, \"total\": 0},\n",
    "        \"FWH3\": {\"correct\": 0, \"total\": 0},\n",
    "        \"CDRH3\": {\"correct\": 0, \"total\": 0},\n",
    "        \"FWH4\": {\"correct\": 0, \"total\": 0},\n",
    "    }\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        original_seq = row[\"OriginalSequence\"]\n",
    "        masked_seq = row[\"MaskedSequence\"]\n",
    "\n",
    "        original_seq_spaced = add_spaces_preserve_mask(original_seq)\n",
    "        masked_seq_spaced = add_spaces_preserve_mask(masked_seq)\n",
    "        recovered_seq = recover_sequence(masked_seq_spaced, model_unmasker)\n",
    "\n",
    "        original_tokens = original_seq_spaced.split()\n",
    "        masked_tokens = masked_seq_spaced.split()\n",
    "        recovered_tokens = recovered_seq.split()\n",
    "\n",
    "        # Parse CDRH1-3 positions\n",
    "        cdrh1_start, cdrh1_end = eval(row[\"CDRH1_pos\"])\n",
    "        cdrh1_end += 1\n",
    "        cdrh2_start, cdrh2_end = eval(row[\"CDRH2_pos\"])\n",
    "        cdrh2_end += 1\n",
    "        cdrh3_start, cdrh3_end = eval(row[\"CDRH3_pos\"])\n",
    "        cdrh3_end += 1\n",
    "\n",
    "        # Define FWH1-4 regions\n",
    "        fwh1_start, fwh1_end = 0, cdrh1_start\n",
    "        fwh2_start, fwh2_end = cdrh1_end, cdrh2_start\n",
    "        fwh3_start, fwh3_end = cdrh2_end, cdrh3_start\n",
    "        fwh4_start, fwh4_end = cdrh3_end, len(original_seq)\n",
    "\n",
    "        # Compute accuracy for each region\n",
    "        add_region_accuracy(region_accuracies, fwh1_start, fwh1_end, \"FWH1\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, cdrh1_start, cdrh1_end, \"CDRH1\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, fwh2_start, fwh2_end, \"FWH2\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, cdrh2_start, cdrh2_end, \"CDRH2\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, fwh3_start, fwh3_end, \"FWH3\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, cdrh3_start, cdrh3_end, \"CDRH3\", original_tokens, masked_tokens, recovered_tokens)\n",
    "        add_region_accuracy(region_accuracies, fwh4_start, fwh4_end, \"FWH4\", original_tokens, masked_tokens, recovered_tokens)\n",
    "\n",
    "    # Calculate final accuracy for each region\n",
    "    for region, counts in region_accuracies.items():\n",
    "        total = counts[\"total\"]\n",
    "        correct = counts[\"correct\"]\n",
    "        region_accuracies[region][\"accuracy\"] = correct / total if total > 0 else 0\n",
    "\n",
    "    return region_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Load test dataset\n",
    "file_path = \"./data/annotation/updated_test_masked_dataset.csv\" \n",
    "test_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Pretrained ProtBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained ProtBERT overall accuracy on Masked Tokens: 70.31%\n",
      "Pretrained ProtBERT overall error Rate on Masked Tokens: 29.69%\n",
      "Region FWH1 Accuracy: 86.56%\n",
      "Region CDRH1 Accuracy: 41.75%\n",
      "Region FWH2 Accuracy: 73.47%\n",
      "Region CDRH2 Accuracy: 41.13%\n",
      "Region FWH3 Accuracy: 86.60%\n",
      "Region CDRH3 Accuracy: 18.17%\n",
      "Region FWH4 Accuracy: 88.49%\n"
     ]
    }
   ],
   "source": [
    "# Load ProtBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "pretrained_unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Run recovery and calculate overall accuracy\n",
    "pretrained_recovered_sequences, pretrained_overall_accuracy, pretrained_overall_error_rate = calculate_accuracy_and_recover(test_data, pretrained_unmasker)\n",
    "\n",
    "test_data[\"RecoveredSequence\"] = pretrained_recovered_sequences\n",
    "test_data.to_csv(\"recovered_results_vanilla.csv\", index=False)\n",
    "\n",
    "print(f\"Pretrained ProtBERT overall accuracy on Masked Tokens: {pretrained_overall_accuracy:.2%}\")\n",
    "print(f\"Pretrained ProtBERT overall error Rate on Masked Tokens: {pretrained_overall_error_rate:.2%}\")\n",
    "\n",
    "# Calculate region-level accuracy\n",
    "pretrained_region_accuracies = calculate_accuracy_by_region(test_data.iloc[0:428], pretrained_unmasker)\n",
    "for region, counts in pretrained_region_accuracies.items():\n",
    "    print(f\"Region {region} Accuracy: {counts['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: unfreeze all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model2 overall accuracy on Masked Tokens: 90.25%\n",
      "Model2 overall error Rate on Masked Tokens: 9.75%\n",
      "Region FWH1 Accuracy: 95.12%\n",
      "Region CDRH1 Accuracy: 82.50%\n",
      "Region FWH2 Accuracy: 94.31%\n",
      "Region CDRH2 Accuracy: 81.99%\n",
      "Region FWH3 Accuracy: 94.86%\n",
      "Region CDRH3 Accuracy: 71.71%\n",
      "Region FWH4 Accuracy: 97.17%\n"
     ]
    }
   ],
   "source": [
    "# Load fine tuned model 2\n",
    "save_directory = \"./fine_tuned_ProtBERT/model2\"\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory, do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(save_directory)\n",
    "model2_unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Run recovery and calculate overall accuracy\n",
    "model2_recovered_sequences, model2_overall_accuracy, model2_overall_error_rate = calculate_accuracy_and_recover(test_data, model2_unmasker)\n",
    "\n",
    "test_data[\"RecoveredSequence\"] = model2_recovered_sequences\n",
    "test_data.to_csv(\"recovered_results_model2.csv\", index=False)\n",
    "\n",
    "print(f\"Model2 overall accuracy on Masked Tokens: {model2_overall_accuracy:.2%}\")\n",
    "print(f\"Model2 overall error Rate on Masked Tokens: {model2_overall_error_rate:.2%}\")\n",
    "\n",
    "# Calculate region-level accuracy\n",
    "model2_region_accuracies = calculate_accuracy_by_region(test_data.iloc[0:428], model2_unmasker)\n",
    "for region, counts in model2_region_accuracies.items():\n",
    "    print(f\"Region {region} Accuracy: {counts['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: unfreeze last two encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3 accuracy on Masked Tokens: 83.31%\n",
      "Model3 error Rate on Masked Tokens: 16.69%\n",
      "Region FWH1 Accuracy: 92.88%\n",
      "Region CDRH1 Accuracy: 70.75%\n",
      "Region FWH2 Accuracy: 89.63%\n",
      "Region CDRH2 Accuracy: 62.63%\n",
      "Region FWH3 Accuracy: 91.96%\n",
      "Region CDRH3 Accuracy: 49.02%\n",
      "Region FWH4 Accuracy: 96.79%\n"
     ]
    }
   ],
   "source": [
    "# Load fine tuned model 3\n",
    "save_directory = \"./fine_tuned_ProtBERT/model3\"\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory, do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(save_directory)\n",
    "model3_unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Run recovery and calculate overall accuracy\n",
    "model3_recovered_sequences, model3_overall_accuracy, model3_oveall_error_rate = calculate_accuracy_and_recover(test_data, model3_unmasker)\n",
    "\n",
    "test_data[\"RecoveredSequence\"] = model3_recovered_sequences\n",
    "test_data.to_csv(\"recovered_results_model3.csv\", index=False)\n",
    "\n",
    "print(f\"Model3 accuracy on Masked Tokens: {model3_overall_accuracy:.2%}\")\n",
    "print(f\"Model3 error Rate on Masked Tokens: {model3_oveall_error_rate:.2%}\")\n",
    "\n",
    "# Calculate region-level accuracy\n",
    "model3_region_accuracies = calculate_accuracy_by_region(test_data.iloc[0:428], model3_unmasker)\n",
    "for region, counts in model3_region_accuracies.items():\n",
    "    print(f\"Region {region} Accuracy: {counts['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-Perplexity (PPPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate PPPL for each BERT-based model\n",
    "def compute_pppl(sequence, model, tokenizer):\n",
    "    input_ids = tokenizer(sequence, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    num_tokens = input_ids.size(1) - 2  # Exclude [CLS] and [SEP]\n",
    "    total_log_prob = 0.0\n",
    "\n",
    "    for i in range(1, num_tokens + 1):  # Iterate through each token (excluding special tokens)\n",
    "        masked_input = input_ids.clone()\n",
    "        masked_input[0, i] = tokenizer.mask_token_id  # Mask the i-th token\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(masked_input)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        softmax_probs = torch.nn.functional.softmax(logits[0, i], dim=-1)\n",
    "        original_token_id = input_ids[0, i]\n",
    "        token_prob = softmax_probs[original_token_id].item()\n",
    "\n",
    "        if token_prob > 0:\n",
    "            total_log_prob += math.log(token_prob)\n",
    "\n",
    "    pppl = math.exp(-total_log_prob / num_tokens)\n",
    "    return pppl\n",
    "\n",
    "\n",
    "def compute_pppl_for_dataset(test_data, model, tokenizer):\n",
    "    pppl_scores = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for sequence in test_data[\"OriginalSequence\"]:\n",
    "        sequence = add_spaces_preserve_mask(sequence)\n",
    "        pppl = compute_pppl(sequence, model, tokenizer)\n",
    "        pppl_scores.append(pppl)\n",
    "\n",
    "    avg_pppl = sum(pppl_scores) / len(pppl_scores)\n",
    "\n",
    "    return avg_pppl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Pretrained ProtBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PPPL for Pretrained ProtBERT: 2.980614575856263\n"
     ]
    }
   ],
   "source": [
    "pretrained_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "pretained_model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "pretrained_avg_pppl = compute_pppl_for_dataset(test_data, pretained_model, pretrained_tokenizer)\n",
    "\n",
    "print(f\"Average PPPL for Pretrained ProtBERT: {pretrained_avg_pppl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: unfreeze all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PPPL for Model2: 1.4402317786021814\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"./fine_tuned_ProtBERT/model2\"\n",
    "model2_tokenizer = BertTokenizer.from_pretrained(save_directory, do_lower_case=False)\n",
    "model2 = BertForMaskedLM.from_pretrained(save_directory)\n",
    "\n",
    "model2_avg_pppl = compute_pppl_for_dataset(test_data, model2, model2_tokenizer)\n",
    "\n",
    "print(f\"Average PPPL for Model2: {model2_avg_pppl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: unfreeze last two encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PPPL for Model3: 1.8949705332376572\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"./fine_tuned_ProtBERT/model3\"\n",
    "model3_tokenizer = BertTokenizer.from_pretrained(save_directory, do_lower_case=False)\n",
    "model3 = BertForMaskedLM.from_pretrained(save_directory)\n",
    "\n",
    "model3_avg_pppl = compute_pppl_for_dataset(test_data, model3, model3_tokenizer)\n",
    "\n",
    "print(f\"Average PPPL for Model3: {model3_avg_pppl}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
